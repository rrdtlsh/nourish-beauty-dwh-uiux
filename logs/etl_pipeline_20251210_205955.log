2025-12-10 20:59:55,654 - __main__ - INFO - ================================================================================
2025-12-10 20:59:55,655 - __main__ - INFO - NOURISH BEAUTY DATA WAREHOUSE - ETL PIPELINE
2025-12-10 20:59:55,656 - __main__ - INFO -    Author: Raudatul Sholehah - 2310817220002
2025-12-10 20:59:55,656 - __main__ - INFO -    Date: 2025-12-10 20:59:55
2025-12-10 20:59:55,657 - __main__ - INFO - ================================================================================
2025-12-10 20:59:55,657 - __main__ - INFO - 
2025-12-10 20:59:55,657 - __main__ - INFO - STEP 1: Testing Database Connection
2025-12-10 20:59:55,658 - __main__ - INFO - --------------------------------------------------------------------------------
2025-12-10 20:59:55,948 - __main__ - INFO - 
2025-12-10 20:59:55,949 - __main__ - INFO - STEP 2: EXTRACT PHASE
2025-12-10 20:59:55,949 - __main__ - INFO - --------------------------------------------------------------------------------
2025-12-10 20:59:56,270 - __main__ - INFO - Extracting Sales Data...
2025-12-10 20:59:56,270 - etl.extract.extract_sales - INFO - Starting sales data extraction...
2025-12-10 20:59:56,271 - etl.extract.extract_sales - INFO - Reading file: /app/data/raw/SuperMarket-Analysis-penjualan.csv
2025-12-10 20:59:56,282 - etl.extract.extract_sales - INFO - [OK] Loaded 1000 rows from SuperMarket-Analysis-penjualan.csv
2025-12-10 20:59:56,282 - etl.extract.extract_sales - INFO - Applying transformations...
2025-12-10 20:59:56,282 - etl.transform.transform_sales - INFO - Applying 40 transformation rules to sales data...
2025-12-10 20:59:56,282 - etl.transform.transform_sales - INFO -    Initial row count: 1000
2025-12-10 20:59:56,283 - etl.transform.transform_sales - INFO - RULE 0: Pre-cleaning Indonesian number format & USD to IDR conversion...
2025-12-10 20:59:56,284 - etl.transform.transform_sales - INFO -    ✓ Detected USD format (avg: $307.59)
2025-12-10 20:59:56,285 - etl.transform.transform_sales - INFO -    harga_satuan: 74.69 → Rp 1,120,350
2025-12-10 20:59:56,287 - etl.transform.transform_sales - INFO -    pajak_5_persen: 261.415 → Rp 3,921,225
2025-12-10 20:59:56,288 - etl.transform.transform_sales - INFO -    total_penjualan_sebelum_pajak: 522.83 → Rp 7,842,450
2025-12-10 20:59:56,294 - etl.transform.transform_sales - INFO -    pendapatan_kotor: 261.415 → Rp 3,921,225
2025-12-10 20:59:56,295 - etl.transform.transform_sales - INFO -    persentase_gross_margin: 4761904762.00% (kept as percentage)
2025-12-10 20:59:56,295 - etl.transform.transform_sales - INFO - RULE 1-5: Data Type Conversion
2025-12-10 20:59:56,301 - etl.transform.transform_sales - INFO - RULE 6-10: Handle Missing Values
2025-12-10 20:59:56,306 - etl.transform.transform_sales - INFO - RULE 11-15: Data Cleaning
2025-12-10 20:59:56,310 - etl.transform.transform_sales - INFO - RULE 16-20: Standardization
2025-12-10 20:59:56,315 - etl.transform.transform_sales - INFO - RULE 21-25: Calculate Derived Fields
2025-12-10 20:59:56,320 - etl.transform.transform_sales - INFO - RULE 26-30: Validation & Quality Checks
2025-12-10 20:59:56,324 - etl.transform.transform_sales - INFO - RULE 31-35: Business Logic & Categorization
2025-12-10 20:59:56,335 - etl.transform.transform_sales - INFO - RULE 36-40: Final Cleaning & Outlier Removal
2025-12-10 20:59:56,342 - etl.transform.transform_sales - INFO - [OK] Transformation complete!
2025-12-10 20:59:56,343 - etl.transform.transform_sales - INFO -    Initial rows: 1000
2025-12-10 20:59:56,343 - etl.transform.transform_sales - INFO -    Final rows: 991
2025-12-10 20:59:56,343 - etl.transform.transform_sales - INFO -    Removed: 9 (0.9%)
2025-12-10 20:59:56,344 - etl.transform.transform_sales - INFO -    Retention rate: 99.1%
2025-12-10 20:59:56,344 - etl.transform.transform_sales - INFO -    Currency converted: USD → IDR (rate: 15,000)
2025-12-10 20:59:56,344 - etl.transform.transform_sales - INFO - 
   SUMMARY STATISTICS (in IDR):
2025-12-10 20:59:56,345 - etl.transform.transform_sales - INFO -    - Total Revenue: Rp 4,502,404,650
2025-12-10 20:59:56,345 - etl.transform.transform_sales - INFO -    - Avg Transaction: Rp 4,543,294
2025-12-10 20:59:56,347 - etl.transform.transform_sales - INFO -    - Min Transaction: Rp 152,550
2025-12-10 20:59:56,347 - etl.transform.transform_sales - INFO -    - Max Transaction: Rp 14,895,000
2025-12-10 20:59:56,374 - etl.extract.extract_sales - INFO - [OK] Saved to staging file: /app/data/staging/staging_sales.csv
2025-12-10 20:59:56,374 - etl.extract.extract_sales - INFO - [OK] Extraction complete: 991 records ready
2025-12-10 20:59:56,375 - etl.extract.extract_sales - INFO - 
Loading sales data to staging_sales table...
2025-12-10 20:59:56,375 - etl.extract.extract_sales - INFO -    Records to load: 991
2025-12-10 20:59:56,376 - etl.extract.extract_sales - INFO -    Truncating staging_sales table...
2025-12-10 20:59:56,535 - etl.extract.extract_sales - INFO -    Original shape: (991, 17)
2025-12-10 20:59:56,535 - etl.extract.extract_sales - INFO -    Original columns: ['id_invoice', 'cabang', 'kota', 'tipe_customer', 'jenis_kelamin', 'kategori_produk', 'harga_satuan', 'jumlah', 'pajak_5_persen', 'tanggal', 'waktu', 'metode_pembayaran', 'total_penjualan_sebelum_pajak', 'persentase_gross_margin', 'pendapatan_kotor', 'rating', 'load_timestamp']
2025-12-10 20:59:56,537 - etl.extract.extract_sales - INFO -    Clean shape: (991, 17)
2025-12-10 20:59:56,537 - etl.extract.extract_sales - INFO -    Clean columns: ['id_invoice', 'cabang', 'kota', 'tipe_customer', 'jenis_kelamin', 'kategori_produk', 'harga_satuan', 'jumlah', 'pajak_5_persen', 'tanggal', 'waktu', 'metode_pembayaran', 'total_penjualan_sebelum_pajak', 'persentase_gross_margin', 'pendapatan_kotor', 'rating', 'load_timestamp']
2025-12-10 20:59:56,540 - etl.extract.extract_sales - INFO -    Loading data in 10 chunks of 100 rows...
2025-12-10 20:59:56,593 - etl.extract.extract_sales - INFO -    ✓ Chunk 1/10 loaded (100 rows, total: 100)
2025-12-10 20:59:56,624 - etl.extract.extract_sales - INFO -    ✓ Chunk 2/10 loaded (100 rows, total: 200)
2025-12-10 20:59:56,658 - etl.extract.extract_sales - INFO -    ✓ Chunk 3/10 loaded (100 rows, total: 300)
2025-12-10 20:59:56,690 - etl.extract.extract_sales - INFO -    ✓ Chunk 4/10 loaded (100 rows, total: 400)
2025-12-10 20:59:56,730 - etl.extract.extract_sales - INFO -    ✓ Chunk 5/10 loaded (100 rows, total: 500)
2025-12-10 20:59:56,762 - etl.extract.extract_sales - INFO -    ✓ Chunk 6/10 loaded (100 rows, total: 600)
2025-12-10 20:59:56,794 - etl.extract.extract_sales - INFO -    ✓ Chunk 7/10 loaded (100 rows, total: 700)
2025-12-10 20:59:56,823 - etl.extract.extract_sales - INFO -    ✓ Chunk 8/10 loaded (100 rows, total: 800)
2025-12-10 20:59:56,892 - etl.extract.extract_sales - INFO -    ✓ Chunk 9/10 loaded (100 rows, total: 900)
2025-12-10 20:59:56,923 - etl.extract.extract_sales - INFO -    ✓ Chunk 10/10 loaded (91 rows, total: 991)
2025-12-10 20:59:56,924 - etl.extract.extract_sales - INFO - [OK] Successfully loaded 991 rows to staging_sales
2025-12-10 20:59:56,928 - etl.extract.extract_sales - INFO - [OK] Verified staging_sales row count: 991
2025-12-10 20:59:56,931 - etl.extract.extract_sales - INFO - [OK] Stats: Rows=991, Avg=Rp 4,543,294, Min=Rp 152,550, Max=Rp 14,895,000
2025-12-10 20:59:56,932 - __main__ - INFO - Extracting HR Data...
2025-12-10 20:59:56,933 - etl.extract.extract_hr - INFO - Starting HR data extraction...
2025-12-10 20:59:56,933 - etl.extract.extract_hr - INFO - Reading file: /app/data/raw/HRDataset.csv
2025-12-10 20:59:56,949 - etl.extract.extract_hr - INFO - [OK] Loaded 311 rows from HRDataset.csv
2025-12-10 20:59:56,949 - etl.extract.extract_hr - INFO -    Columns: 36
2025-12-10 20:59:56,950 - etl.extract.extract_hr - INFO -    Converting date column: dob
2025-12-10 20:59:56,953 - etl.extract.extract_hr - INFO -    Converting date column: dateofhire
2025-12-10 20:59:56,956 - etl.extract.extract_hr - INFO -    Converting date column: dateoftermination
2025-12-10 20:59:56,957 - etl.extract.extract_hr - INFO -    Converting date column: lastperformancereview_date
2025-12-10 20:59:56,979 - etl.extract.extract_hr - INFO - [OK] Saved to staging file: /app/data/staging/staging_hr.csv
2025-12-10 20:59:56,979 - etl.extract.extract_hr - INFO - [OK] Extraction complete: 311 records ready
2025-12-10 20:59:56,980 - etl.extract.extract_hr - INFO - Loading HR data to staging_hr table...
2025-12-10 20:59:56,980 - etl.extract.extract_hr - INFO -    Records to load: 311
2025-12-10 20:59:56,981 - etl.extract.extract_hr - INFO -    Truncating staging_hr table...
2025-12-10 20:59:57,041 - etl.extract.extract_hr - INFO -    Loading rows individually...
2025-12-10 20:59:57,584 - etl.extract.extract_hr - INFO -    Progress: 50/311 rows loaded
2025-12-10 20:59:58,529 - etl.extract.extract_hr - INFO -    Progress: 100/311 rows loaded
2025-12-10 20:59:59,256 - etl.extract.extract_hr - INFO -    Progress: 150/311 rows loaded
2025-12-10 21:00:00,243 - etl.extract.extract_hr - INFO -    Progress: 200/311 rows loaded
2025-12-10 21:00:01,017 - etl.extract.extract_hr - INFO -    Progress: 250/311 rows loaded
2025-12-10 21:00:01,682 - etl.extract.extract_hr - INFO -    Progress: 300/311 rows loaded
2025-12-10 21:00:01,875 - etl.extract.extract_hr - INFO -    Progress: 311/311 rows loaded
2025-12-10 21:00:01,875 - etl.extract.extract_hr - INFO - [OK] Successfully loaded 311 rows
2025-12-10 21:00:01,881 - etl.extract.extract_hr - INFO - [OK] Verified row count: 311
2025-12-10 21:00:01,883 - __main__ - INFO - Extracting Marketing Data...
2025-12-10 21:00:01,884 - etl.extract.extract_marketing - INFO - Starting marketing data extraction...
2025-12-10 21:00:01,884 - etl.extract.extract_marketing - INFO - Reading file: /app/data/raw/marketing_campaign.csv
2025-12-10 21:00:01,884 - etl.extract.extract_marketing - INFO -    Trying delimiter: '	'
2025-12-10 21:00:01,901 - etl.extract.extract_marketing - WARNING -    Failed: only 1 columns detected
2025-12-10 21:00:01,901 - etl.extract.extract_marketing - INFO -    Trying delimiter: ';'
2025-12-10 21:00:01,932 - etl.extract.extract_marketing - INFO -    [OK] Successfully read with delimiter ';'
2025-12-10 21:00:01,932 - etl.extract.extract_marketing - INFO -    Columns detected: 29
2025-12-10 21:00:01,933 - etl.extract.extract_marketing - INFO - [OK] Loaded 1000 rows from marketing_campaign.csv
2025-12-10 21:00:01,933 - etl.extract.extract_marketing - INFO -    Columns: ['ID', 'Year_Birth', 'Education', 'Marital_Status', 'Income']... (29 total)
2025-12-10 21:00:01,935 - etl.extract.extract_marketing - INFO -    Converting date column: dt_customer
2025-12-10 21:00:01,987 - etl.extract.extract_marketing - INFO - [OK] Saved to staging file: /app/data/staging/staging_marketing.csv
2025-12-10 21:00:01,987 - etl.extract.extract_marketing - INFO - [OK] Extraction complete: 1000 records ready
2025-12-10 21:00:01,988 - etl.extract.extract_marketing - INFO - Loading marketing data to staging_marketing table...
2025-12-10 21:00:01,988 - etl.extract.extract_marketing - INFO -    Records to load: 1000
2025-12-10 21:00:01,989 - etl.extract.extract_marketing - INFO -    Dropping and recreating staging_marketing table...
2025-12-10 21:00:02,088 - etl.extract.extract_marketing - INFO -    Loading data with auto-schema detection...
2025-12-10 21:00:02,513 - etl.extract.extract_marketing - INFO - [OK] Successfully loaded 1000 rows
2025-12-10 21:00:02,516 - etl.extract.extract_marketing - INFO - [OK] Verified row count: 1000
2025-12-10 21:00:02,517 - __main__ - INFO - [OK] Extract phase completed!
2025-12-10 21:00:02,517 - __main__ - INFO - 
2025-12-10 21:00:02,518 - __main__ - INFO - STEP 3: TRANSFORM PHASE
2025-12-10 21:00:02,518 - __main__ - INFO - --------------------------------------------------------------------------------
2025-12-10 21:00:02,518 - __main__ - INFO - Transformation rules will be applied during load phase
2025-12-10 21:00:02,518 - __main__ - INFO - [OK] 40 transformation rules ready
2025-12-10 21:00:02,519 - __main__ - INFO - 
2025-12-10 21:00:02,519 - __main__ - INFO - STEP 4: LOAD DIMENSIONS
2025-12-10 21:00:02,519 - __main__ - INFO - --------------------------------------------------------------------------------
2025-12-10 21:00:02,523 - etl.load.load_dimensions - INFO - ======================================================================
2025-12-10 21:00:02,523 - etl.load.load_dimensions - INFO - STARTING DIMENSION LOAD PROCESS
2025-12-10 21:00:02,524 - etl.load.load_dimensions - INFO - ======================================================================
2025-12-10 21:00:02,524 - etl.load.load_dimensions - INFO - Loading dim_produk...
2025-12-10 21:00:02,629 - etl.load.load_dimensions - INFO - [OK] Loaded 6 products to dim_produk
2025-12-10 21:00:02,630 - etl.load.load_dimensions - INFO - Loading dim_customer...
2025-12-10 21:00:02,688 - etl.load.load_dimensions - INFO -    Truncated dim_customer table
2025-12-10 21:00:02,747 - etl.load.load_dimensions - INFO -    Loaded chunk 1: 50 rows (Total: 50/1000)
2025-12-10 21:00:02,764 - etl.load.load_dimensions - INFO -    Loaded chunk 2: 50 rows (Total: 100/1000)
2025-12-10 21:00:02,780 - etl.load.load_dimensions - INFO -    Loaded chunk 3: 50 rows (Total: 150/1000)
2025-12-10 21:00:02,836 - etl.load.load_dimensions - INFO -    Loaded chunk 4: 50 rows (Total: 200/1000)
2025-12-10 21:00:02,908 - etl.load.load_dimensions - INFO -    Loaded chunk 5: 50 rows (Total: 250/1000)
2025-12-10 21:00:02,929 - etl.load.load_dimensions - INFO -    Loaded chunk 6: 50 rows (Total: 300/1000)
2025-12-10 21:00:02,944 - etl.load.load_dimensions - INFO -    Loaded chunk 7: 50 rows (Total: 350/1000)
2025-12-10 21:00:02,961 - etl.load.load_dimensions - INFO -    Loaded chunk 8: 50 rows (Total: 400/1000)
2025-12-10 21:00:02,982 - etl.load.load_dimensions - INFO -    Loaded chunk 9: 50 rows (Total: 450/1000)
2025-12-10 21:00:03,002 - etl.load.load_dimensions - INFO -    Loaded chunk 10: 50 rows (Total: 500/1000)
2025-12-10 21:00:03,028 - etl.load.load_dimensions - INFO -    Loaded chunk 11: 50 rows (Total: 550/1000)
2025-12-10 21:00:03,050 - etl.load.load_dimensions - INFO -    Loaded chunk 12: 50 rows (Total: 600/1000)
2025-12-10 21:00:03,077 - etl.load.load_dimensions - INFO -    Loaded chunk 13: 50 rows (Total: 650/1000)
2025-12-10 21:00:03,110 - etl.load.load_dimensions - INFO -    Loaded chunk 14: 50 rows (Total: 700/1000)
2025-12-10 21:00:03,132 - etl.load.load_dimensions - INFO -    Loaded chunk 15: 50 rows (Total: 750/1000)
2025-12-10 21:00:03,160 - etl.load.load_dimensions - INFO -    Loaded chunk 16: 50 rows (Total: 800/1000)
2025-12-10 21:00:03,193 - etl.load.load_dimensions - INFO -    Loaded chunk 17: 50 rows (Total: 850/1000)
2025-12-10 21:00:03,218 - etl.load.load_dimensions - INFO -    Loaded chunk 18: 50 rows (Total: 900/1000)
2025-12-10 21:00:03,259 - etl.load.load_dimensions - INFO -    Loaded chunk 19: 50 rows (Total: 950/1000)
2025-12-10 21:00:03,290 - etl.load.load_dimensions - INFO -    Loaded chunk 20: 50 rows (Total: 1000/1000)
2025-12-10 21:00:03,293 - etl.load.load_dimensions - INFO - [OK] Successfully loaded 1000 customers to dim_customer
2025-12-10 21:00:03,298 - etl.load.load_dimensions - INFO - Loading dim_employee...
2025-12-10 21:00:03,412 - etl.load.load_dimensions - INFO -    Truncated dim_employee table
2025-12-10 21:00:03,420 - etl.load.load_dimensions - ERROR - [ERROR] Error loading dim_employee: (psycopg2.errors.DatatypeMismatch) COALESCE types text and date cannot be matched
LINE 12: ...              EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DA...
                                                              ^

[SQL: 
            SELECT DISTINCT
                empid as emp_id,
                employee_name,
                position,
                department,
                managername as manager_name,
                managerid as manager_id,
                sex,
                maritaldesc as marital_desc,
                dob,
                EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DATE))) as age,
                dateofhire as date_of_hire,
                employmentstatus as employment_status,
                salary,
                CASE WHEN employmentstatus = 'Active' THEN TRUE ELSE FALSE END as is_active,
                NOW() as created_date,
                NOW() as updated_date
            FROM staging_hr
            WHERE empid IS NOT NULL
            ]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-12-10 21:00:03,429 - etl.load.load_dimensions - ERROR - Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1969, in _exec_single_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 922, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DatatypeMismatch: COALESCE types text and date cannot be matched
LINE 12: ...              EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DA...
                                                              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/etl/load/load_dimensions.py", line 179, in load_dim_employee
    df = pd.read_sql(query, conn)
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/pandas/io/sql.py", line 682, in read_sql
    return pandas_sql.read_query(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/pandas/io/sql.py", line 1776, in read_query
    result = self.execute(sql, params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/pandas/io/sql.py", line 1600, in execute
    return self.con.execute(sql, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1416, in execute
    return meth(
           ^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 516, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1639, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1848, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1988, in _exec_single_context
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2343, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1969, in _exec_single_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 922, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DatatypeMismatch) COALESCE types text and date cannot be matched
LINE 12: ...              EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DA...
                                                              ^

[SQL: 
            SELECT DISTINCT
                empid as emp_id,
                employee_name,
                position,
                department,
                managername as manager_name,
                managerid as manager_id,
                sex,
                maritaldesc as marital_desc,
                dob,
                EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DATE))) as age,
                dateofhire as date_of_hire,
                employmentstatus as employment_status,
                salary,
                CASE WHEN employmentstatus = 'Active' THEN TRUE ELSE FALSE END as is_active,
                NOW() as created_date,
                NOW() as updated_date
            FROM staging_hr
            WHERE empid IS NOT NULL
            ]
(Background on this error at: https://sqlalche.me/e/20/f405)

2025-12-10 21:00:03,430 - etl.load.load_dimensions - ERROR - ======================================================================
2025-12-10 21:00:03,431 - etl.load.load_dimensions - ERROR - [ERROR] DIMENSION LOAD FAILED: (psycopg2.errors.DatatypeMismatch) COALESCE types text and date cannot be matched
LINE 12: ...              EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DA...
                                                              ^

[SQL: 
            SELECT DISTINCT
                empid as emp_id,
                employee_name,
                position,
                department,
                managername as manager_name,
                managerid as manager_id,
                sex,
                maritaldesc as marital_desc,
                dob,
                EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DATE))) as age,
                dateofhire as date_of_hire,
                employmentstatus as employment_status,
                salary,
                CASE WHEN employmentstatus = 'Active' THEN TRUE ELSE FALSE END as is_active,
                NOW() as created_date,
                NOW() as updated_date
            FROM staging_hr
            WHERE empid IS NOT NULL
            ]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-12-10 21:00:03,431 - etl.load.load_dimensions - ERROR - ======================================================================
2025-12-10 21:00:03,435 - etl.load.load_dimensions - ERROR - Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1969, in _exec_single_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 922, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DatatypeMismatch: COALESCE types text and date cannot be matched
LINE 12: ...              EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DA...
                                                              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/etl/load/load_dimensions.py", line 259, in load_all_dimensions
    load_dim_employee()
  File "/app/etl/load/load_dimensions.py", line 179, in load_dim_employee
    df = pd.read_sql(query, conn)
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/pandas/io/sql.py", line 682, in read_sql
    return pandas_sql.read_query(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/pandas/io/sql.py", line 1776, in read_query
    result = self.execute(sql, params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/pandas/io/sql.py", line 1600, in execute
    return self.con.execute(sql, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1416, in execute
    return meth(
           ^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 516, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1639, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1848, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1988, in _exec_single_context
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2343, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1969, in _exec_single_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 922, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DatatypeMismatch) COALESCE types text and date cannot be matched
LINE 12: ...              EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DA...
                                                              ^

[SQL: 
            SELECT DISTINCT
                empid as emp_id,
                employee_name,
                position,
                department,
                managername as manager_name,
                managerid as manager_id,
                sex,
                maritaldesc as marital_desc,
                dob,
                EXTRACT(YEAR FROM age(COALESCE(dob, CURRENT_DATE))) as age,
                dateofhire as date_of_hire,
                employmentstatus as employment_status,
                salary,
                CASE WHEN employmentstatus = 'Active' THEN TRUE ELSE FALSE END as is_active,
                NOW() as created_date,
                NOW() as updated_date
            FROM staging_hr
            WHERE empid IS NOT NULL
            ]
(Background on this error at: https://sqlalche.me/e/20/f405)

2025-12-10 21:00:03,435 - __main__ - INFO - 
2025-12-10 21:00:03,436 - __main__ - INFO - STEP 5: LOAD FACT TABLES
2025-12-10 21:00:03,436 - __main__ - INFO - --------------------------------------------------------------------------------
2025-12-10 21:00:03,437 - etl.load.load_facts - INFO - ======================================================================
2025-12-10 21:00:03,437 - etl.load.load_facts - INFO - STARTING FACT TABLES LOAD PROCESS
2025-12-10 21:00:03,438 - etl.load.load_facts - INFO - ======================================================================
2025-12-10 21:00:03,439 - etl.load.load_facts - INFO - Loading fact_sales...
2025-12-10 21:00:03,588 - etl.load.load_facts - INFO - [OK] Loaded 991 rows to fact_sales
2025-12-10 21:00:03,589 - etl.load.load_facts - INFO - Loading fact_marketing_response...
2025-12-10 21:00:03,652 - etl.load.load_facts - INFO -    Debug - Marketing: 1000 rows, dates: 2012-08-01 to 2014-06-29
2025-12-10 21:00:03,653 - etl.load.load_facts - INFO -    Debug - dim_tanggal: 5560 dates, range: 2005-01-09 to 2020-03-30
2025-12-10 21:00:03,653 - etl.load.load_facts - INFO -    Debug - Matching rows after JOIN: 1000
2025-12-10 21:00:03,684 - etl.load.load_facts - INFO - [OK] Loaded 1000 rows to fact_marketing_response
2025-12-10 21:00:03,684 - etl.load.load_facts - INFO - Loading fact_employee_performance...
2025-12-10 21:00:03,747 - etl.load.load_facts - INFO - [OK] Loaded 0 rows to fact_employee_performance
2025-12-10 21:00:03,748 - etl.load.load_facts - INFO - Verifying fact tables...
2025-12-10 21:00:03,834 - etl.load.load_facts - INFO - ======================================================================
2025-12-10 21:00:03,835 - etl.load.load_facts - INFO - [OK] ALL FACT TABLES LOADED SUCCESSFULLY!
2025-12-10 21:00:03,836 - etl.load.load_facts - INFO - Total time: 0.40 seconds
2025-12-10 21:00:03,836 - etl.load.load_facts - INFO - ======================================================================
2025-12-10 21:00:03,837 - __main__ - INFO - 
2025-12-10 21:00:03,837 - __main__ - INFO - STEP 6: EXPORT TO DATA LAKE
2025-12-10 21:00:03,838 - __main__ - INFO - --------------------------------------------------------------------------------
2025-12-10 21:00:03,838 - __main__ - INFO - Bronze Layer: Raw files already in data/lake/raw/
2025-12-10 21:00:03,838 - __main__ - INFO - Exporting to Silver Layer (Processed)...
2025-12-10 21:00:03,842 - etl.export_to_silver_layer - INFO -   → cleaned_sales.parquet
2025-12-10 21:00:04,099 - etl.export_to_silver_layer - INFO -      Exported 991 rows
2025-12-10 21:00:04,099 - etl.export_to_silver_layer - INFO -   → cleaned_hr.parquet
2025-12-10 21:00:04,165 - etl.export_to_silver_layer - INFO -      Exported 311 rows
2025-12-10 21:00:04,166 - etl.export_to_silver_layer - INFO -   → cleaned_marketing.parquet
2025-12-10 21:00:04,228 - etl.export_to_silver_layer - INFO -      Exported 1000 rows
2025-12-10 21:00:04,233 - etl.export_to_silver_layer - INFO - ✅ Silver layer: 3 files created in data/lake/processed
2025-12-10 21:00:04,233 - __main__ - INFO - ✅ Silver layer export completed
2025-12-10 21:00:04,233 - __main__ - INFO - Exporting to Gold Layer (Curated)...
2025-12-10 21:00:04,236 - etl.export_to_gold_layer - INFO -   → sales_metrics_daily.parquet
2025-12-10 21:00:04,314 - etl.export_to_gold_layer - INFO -      Exported 263 rows
2025-12-10 21:00:04,314 - etl.export_to_gold_layer - INFO -   → product_performance.parquet
2025-12-10 21:00:04,338 - etl.export_to_gold_layer - INFO -      Exported 6 rows
2025-12-10 21:00:04,339 - etl.export_to_gold_layer - INFO -   → branch_performance.parquet
2025-12-10 21:00:04,365 - etl.export_to_gold_layer - INFO -      Exported 3 rows
2025-12-10 21:00:04,365 - etl.export_to_gold_layer - INFO -   → payment_analysis.parquet
2025-12-10 21:00:04,390 - etl.export_to_gold_layer - INFO -      Exported 3 rows
2025-12-10 21:00:04,390 - etl.export_to_gold_layer - INFO -   → customer_demographics.parquet
2025-12-10 21:00:04,413 - etl.export_to_gold_layer - INFO -      Exported 4 rows
2025-12-10 21:00:04,414 - etl.export_to_gold_layer - INFO -   → sales_time_patterns.parquet
2025-12-10 21:00:04,434 - etl.export_to_gold_layer - INFO -      Exported 11 rows
2025-12-10 21:00:04,437 - etl.export_to_gold_layer - INFO - ✅ Gold layer: 6 files created in data/lake/curated
2025-12-10 21:00:04,438 - __main__ - INFO - ✅ Gold layer export completed
2025-12-10 21:00:04,438 - __main__ - INFO - [OK] Data Lake export phase completed!
2025-12-10 21:00:04,439 - __main__ - INFO - 
2025-12-10 21:00:04,439 - __main__ - INFO - STEP 7: DATA VERIFICATION
2025-12-10 21:00:04,439 - __main__ - INFO - --------------------------------------------------------------------------------
2025-12-10 21:00:04,606 - __main__ - INFO - 
Data Warehouse Row Counts:
2025-12-10 21:00:04,607 - __main__ - INFO - 
               table_name  row_count
               dim_cabang          7
             dim_customer       1000
             dim_employee          0
              dim_payment          6
               dim_produk         12
              dim_tanggal       5560
fact_employee_performance          0
  fact_marketing_response       1000
               fact_sales        991
2025-12-10 21:00:04,607 - __main__ - INFO - 
Data Lake Status:
2025-12-10 21:00:04,615 - __main__ - INFO -   Bronze Layer: 3 files
2025-12-10 21:00:04,616 - __main__ - INFO -   Silver Layer: 3 files
2025-12-10 21:00:04,616 - __main__ - INFO -   Gold Layer: 6 files
2025-12-10 21:00:04,616 - __main__ - INFO - 
2025-12-10 21:00:04,616 - __main__ - INFO - ================================================================================
2025-12-10 21:00:04,617 - __main__ - INFO - [OK] ETL PIPELINE COMPLETED SUCCESSFULLY!
2025-12-10 21:00:04,617 - __main__ - INFO - ================================================================================
2025-12-10 21:00:04,617 - __main__ - INFO - Log file: logs/etl_pipeline_20251210_205955.log
2025-12-10 21:00:04,617 - __main__ - INFO - Duration: 8.96 seconds
2025-12-10 21:00:04,618 - __main__ - INFO - Completed at: 2025-12-10 21:00:04
2025-12-10 21:00:04,618 - __main__ - INFO - ================================================================================
